{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_BHPTNRSur = \"/home/ubuntu/EG-CA/BHPTNRSurrogate\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# add the path to the script directory\n",
    "sys.path.append(PATH_TO_BHPTNRSur)\n",
    "from surrogates import BHPTNRSur1dq1e4 as bhptsur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsur, hsur = bhptsur.generate_surrogate(q=2.5, M_tot=60, dist_mpc=10000)\n",
    "print(hsur[(2,2)][0])\n",
    "\n",
    "#print(hsur.keys())\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(tsur, np.real(hsur[(2,2)]), '-', label='22')\n",
    "plt.plot(tsur, np.real(hsur[(3,3)]), '-', label='33')\n",
    "plt.xlabel('time [seconds]', fontsize=15)\n",
    "plt.ylabel('rh/M', fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import architectures as arch\n",
    "from functools import partial\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from torchvision.ops import MLP\n",
    "from running import train_one_epoch, evaluate_refinement\n",
    "from data import setup_waveform_dataloaders, WaveformDataset, load_bhpt_tensors\n",
    "from architectures import SingleConvNeuralNet, GalerkinTransformer\n",
    "from bhpt_running import train_one_epoch, evaluate_refinement\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"BHPT training script (core logic excerpt).\")\n",
    "parser.add_argument(\"--data\", type=Path, default=Path(\"bhpt_dataset.mat\"), help=\"Path to the .mat dataset produced by generate_bhpt_dataset.py.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch-size\", type=int, default=8)\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--weight-decay\", type=float, default=1e-4, help=\"Weight decay (L2 penalty) for Adam optimizer.\")\n",
    "parser.add_argument(\"--n-timesteps\", type=int, default=None, help=\"Number of temporal frames to sample from the raw data (consistent with notebook).\")\n",
    "\n",
    "parser.add_argument(\"--share\", action=\"store_true\", help=\"Share weights between modules.\")\n",
    "parser.add_argument(\"--no-share\", dest=\"share\", action=\"store_false\", help=\"Don't share weights between modules.\")\n",
    "parser.set_defaults(share=True)\n",
    "\n",
    "parser.add_argument(\"--refinement\", action=\"store_true\", help=\"Use refinement.\")\n",
    "parser.add_argument(\"--no-refinement\", dest=\"refinement\", action=\"store_false\", help=\"Don't use refinement.\")\n",
    "parser.set_defaults(refinement=True)\n",
    "\n",
    "parser.add_argument(\"--picard\", action=\"store_true\", help=\"Use Picard iterations.\")\n",
    "parser.add_argument(\"--no-picard\", dest=\"picard\", action=\"store_false\", help=\"Don't use Picard iterations.\")\n",
    "parser.set_defaults(picard=True)\n",
    "\n",
    "parser.add_argument(\"--d_model\", type=int, default=63)\n",
    "parser.add_argument(\"--nhead\", type=int, default=4)\n",
    "parser.add_argument(\"--dim_feedforward\", type=int, default=64)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
    "parser.add_argument(\"--n_layers\", type=int, default=4)\n",
    "parser.add_argument(\"--n_modules\", type=int, default=1)\n",
    "parser.add_argument(\"--q\", type=int, default=1)\n",
    "parser.add_argument(\"--r\", type=float, default=0.5)\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data from bhpt_dataset.mat...\n",
      "  Loaded 'h' with shape: (256, 153075, 2)\n",
      "  Loaded and transposed 'q' with shape: (256, 1)\n",
      "Final tensor shapes: waveforms=torch.Size([256, 153075, 1, 1, 2]), params=torch.Size([256, 1])\n",
      "DataLoaders are ready.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Load data from the .mat file into two tensors\n",
    "waveforms_tensor, params_tensor = load_bhpt_tensors(\n",
    "    args.data, n_timesteps=args.n_timesteps\n",
    ")\n",
    "\n",
    "# 2. Create DataLoaders from the tensors\n",
    "train_loader, val_loader = setup_waveform_dataloaders(\n",
    "    waveforms=waveforms_tensor.to(device),\n",
    "    params=params_tensor.to(device),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "\n",
    "# 3. Define dimensions for the model\n",
    "P = 3  # Positional encoding dimensions (t, y, x)\n",
    "N, T, H, W, Q = waveforms_tensor.shape\n",
    "_, n_params = params_tensor.shape\n",
    "\n",
    "print(\"DataLoaders are ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, Encoder, and Decoder are on device: cuda:0\n",
      "Transformer d_model: 64 (divisible by nhead=4)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Model Definition\n",
    "# For waveform data (H=1, W=1), the \"convolution\" is just a linear projection.\n",
    "# Kernel size K and stride S are (1,1).\n",
    "encoder = SingleConvNeuralNet(dim=Q,\n",
    "    hidden_dim=args.d_model - P,\n",
    "    out_dim=args.d_model - P,\n",
    "    hidden_ff=128,\n",
    "    K=[1, 1],\n",
    "    S=[1, 1])\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Dummy forward pass to get the shape for the decoder\n",
    "with torch.no_grad():\n",
    "    sample_waveforms = waveforms_tensor[0, None, ...].to(device)\n",
    "    _, _, H_prime, W_prime, _ = encoder.forward(sample_waveforms).shape\n",
    "# The decoder's input channels depend on the encoder's output shape\n",
    "decoder_in_channels = H_prime * W_prime * encoder_out_dim\n",
    "\n",
    "# The total dimension fed to the transformer will be d_model + n_params\n",
    "d_model_conditioned = args.d_model + n_params\n",
    "\n",
    "if args.refinement:\n",
    "    make_module = partial(arch.GalerkinTransformer,\n",
    "                          d_model=d_model_conditioned,\n",
    "                          nhead=args.nhead,\n",
    "                          dim_feedforward=args.dim_feedforward,\n",
    "                          dropout=args.dropout,\n",
    "                          n_layers=args.n_layers)\n",
    "    process_trajectory = arch.broadcast_initial_conditions\n",
    "else:\n",
    "    # Autoregressive training is not implemented for the BHPT case yet\n",
    "    raise NotImplementedError(\"Only refinement mode is set up for BHPT training.\")\n",
    "\n",
    "if args.share:\n",
    "    modules = arch.make_weight_shared_modules(make_module, n_modules=args.n_modules)\n",
    "else:\n",
    "    modules = arch.make_weight_unshared_modules(make_module, n_modules=args.n_modules)\n",
    "\n",
    "if args.picard:\n",
    "    model = arch.PicardIterations(modules, q=args.q, r=args.r)\n",
    "else:\n",
    "    model = arch.ArbitraryIterations(modules)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "decoder = MLP(\n",
    "    in_channels=decoder_in_channels,\n",
    "    hidden_channels=[64, 256, H * W * Q], # Final output must match original H, W, Q\n",
    "    activation_layer=nn.ELU,\n",
    ")\n",
    "\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "print(f\"Model, Encoder, and Decoder are on device: {next(model.parameters()).device}\")\n",
    "print(f\"Transformer d_model: {d_model_conditioned} (divisible by nhead={args.nhead})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch   1 | train loss: 0.002059 | val loss: 0.000208\n",
      "Epoch   2 | train loss: 0.000108 | val loss: 0.000042\n",
      "Epoch   3 | train loss: 0.000011 | val loss: 0.000001\n",
      "Epoch   4 | train loss: 0.000001 | val loss: 0.000000\n",
      "Epoch   5 | train loss: 0.000000 | val loss: 0.000000\n",
      "Epoch   6 | train loss: 0.000000 | val loss: 0.000000\n",
      "Epoch   7 | train loss: 0.000000 | val loss: 0.000000\n",
      "Epoch   8 | train loss: 0.000000 | val loss: 0.000000\n",
      "Epoch   9 | train loss: 0.000000 | val loss: 0.000000\n",
      "Epoch  10 | train loss: 0.000000 | val loss: 0.000000\n",
      "\n",
      "Training complete. Saved model weights to bhpt_weights.pt\n"
     ]
    }
   ],
   "source": [
    "# The optimizer needs to know about all trainable parameters\n",
    "all_params = list(model.parameters()) + list(encoder.parameters()) + list(decoder.parameters())\n",
    "optim = torch.optim.Adam(all_params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=args.epochs)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    # Pass nhead to the training and evaluation functions\n",
    "    train_loss = train_one_epoch(model,\n",
    "                                 encoder,\n",
    "                                 decoder,\n",
    "                                 process_trajectory,\n",
    "                                 train_loader,\n",
    "                                 optim)\n",
    "                                 \n",
    "    val_loss = evaluate_refinement(model,\n",
    "                                   encoder,\n",
    "                                   decoder,\n",
    "                                   process_trajectory,\n",
    "                                   val_loader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch:3d} | train loss: {train_loss:.6f} | val loss: {val_loss:.6f}\")\n",
    "\n",
    "torch.save({\"state_dict\": model.state_dict()}, Path(\"bhpt_weights.pt\"))\n",
    "print(\"\\nTraining complete. Saved model weights to bhpt_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
