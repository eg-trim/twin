{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive environ: Jupyter themes not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import architectures as arch\n",
    "from functools import partial\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from torchvision.ops import MLP\n",
    "from data import load_navier_stokes_tensor, setup_dataloaders\n",
    "from training import build_pipeline\n",
    "from training import Trainer\n",
    "from architectures import SingleConvNeuralNet\n",
    "from trim_transformer.transformer_layers import TrimTransformerEncoderLayer, TrimTransformerEncoder\n",
    "import time\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Navierâ€“Stokes training script.\")\n",
    "parser.add_argument(\"--name\", type=str, default=\"test\")\n",
    "parser.add_argument(\"--data\", type=Path, default=Path(\"ns_data.mat\"), help=\"Path to the .mat dataset.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch-size\", type=int, default=8)\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--weight-decay\", type=float, default=1e-4, help=\"Weight decay (L2 penalty) for Adam optimizer.\")\n",
    "parser.add_argument(\"--grad-clip-norm\", type=float, default=1.0, help=\"Gradient clipping norm (set to 0 to disable).\")\n",
    "parser.add_argument(\"--min-lr\", type=float, default=1e-9, help=\"Minimum learning rate for cosine annealing scheduler.\")\n",
    "parser.add_argument(\"--T-max\", type=int, default=101, help=\"Maximum number of iterations for cosine annealing scheduler.\")\n",
    "parser.add_argument(\"--n-timesteps\", type=int, default=11, help=\"Number of temporal frames to sample from the raw data (consistent with notebook).\")\n",
    "\n",
    "parser.add_argument(\"--share\", action=\"store_true\", help=\"Share weights between modules.\")\n",
    "parser.add_argument(\"--no-share\", dest=\"share\", action=\"store_false\", help=\"Don't share weights between modules.\")\n",
    "parser.set_defaults(share=True)\n",
    "\n",
    "parser.add_argument(\"--refinement\", action=\"store_true\", help=\"Use refinement.\")\n",
    "parser.add_argument(\"--no-refinement\", dest=\"refinement\", action=\"store_false\", help=\"Don't use refinement.\")\n",
    "parser.set_defaults(refinement=True)\n",
    "\n",
    "parser.add_argument(\"--picard\", action=\"store_true\", help=\"Use Picard iterations.\")\n",
    "parser.add_argument(\"--no-picard\", dest=\"picard\", action=\"store_false\", help=\"Don't use Picard iterations.\")\n",
    "parser.set_defaults(picard=True)\n",
    "\n",
    "parser.add_argument(\"--d_model\", type=int, default=64)\n",
    "parser.add_argument(\"--nhead\", type=int, default=4)\n",
    "parser.add_argument(\"--dim_feedforward\", type=int, default=64)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
    "parser.add_argument(\"--n_layers\", type=int, default=4)\n",
    "parser.add_argument(\"--n_modules\", type=int, default=4)\n",
    "parser.add_argument(\"--r\", type=float, default=0.5)\n",
    "\n",
    "# Encoder arguments\n",
    "parser.add_argument(\"--encoder-hidden-dim\", type=int, default=None, \n",
    "                    help=\"Hidden dimension for encoder (default: d_model - P)\")\n",
    "parser.add_argument(\"--encoder-hidden-ff\", type=int, default=128,\n",
    "                    help=\"Hidden feedforward dimension for encoder\")\n",
    "parser.add_argument(\"--patch_shape\", type=int, nargs=2, default=[4, 4],\n",
    "                    help=\"A token is a patch of size patch_shape\")\n",
    "\n",
    "# Decoder arguments\n",
    "parser.add_argument(\"--decoder-hidden-channels\", type=int, nargs=\"+\", default=[64, 256],\n",
    "                    help=\"Hidden channels for decoder MLP (excluding final output channel)\")\n",
    "\n",
    "parser.add_argument(\"--train-kind\", choices=[\"acausal\", \"causal_one_step\", \"causal_many_steps\"], default=\"acausal\",\n",
    "                    help=\"Pipeline kind to use during training\")\n",
    "parser.add_argument(\"--val-kind\", choices=[\"acausal\", \"causal_one_step\", \"causal_many_steps\"], default=\"acausal\",\n",
    "                    help=\"Pipeline kind to use during validation\")\n",
    "\n",
    "args = parser.parse_args(\"--epochs 1 --train-kind causal_one_step --val-kind causal_many_steps --no-refinement\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run directory: runs/test/run2\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure\n",
    "Path(\"runs\").mkdir(exist_ok=True)\n",
    "base_dir = Path(\"runs/\" + args.name)\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Find the next available run number\n",
    "run_num = 0\n",
    "while True:\n",
    "    run_dir = base_dir / f\"run{run_num}\"\n",
    "    if not run_dir.exists():\n",
    "        break\n",
    "    run_num += 1\n",
    "\n",
    "# Create the run directory\n",
    "run_dir.mkdir(exist_ok=True)\n",
    "print(f\"Created run directory: {run_dir}\")\n",
    "\n",
    "# Save hyperparameters/config\n",
    "config_dict = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'lr': args.lr,\n",
    "    'weight_decay': args.weight_decay,\n",
    "    'grad_clip_norm': args.grad_clip_norm,\n",
    "    'min_lr': args.min_lr,\n",
    "    'T_max': args.T_max,\n",
    "    'n_timesteps': args.n_timesteps,\n",
    "    'share': args.share,\n",
    "    'refinement': args.refinement,\n",
    "    'picard': args.picard,\n",
    "    'd_model': args.d_model,\n",
    "    'nhead': args.nhead,\n",
    "    'dim_feedforward': args.dim_feedforward,\n",
    "    'dropout': args.dropout,\n",
    "    'n_layers': args.n_layers,\n",
    "    'n_modules': args.n_modules,\n",
    "    'r': args.r,\n",
    "    'encoder_hidden_dim': args.encoder_hidden_dim,\n",
    "    'encoder_hidden_ff': args.encoder_hidden_ff,\n",
    "    'patch_shape': args.patch_shape,\n",
    "    'decoder_hidden_channels': args.decoder_hidden_channels,\n",
    "    'train_kind': args.train_kind,\n",
    "    'val_kind': args.val_kind,\n",
    "}\n",
    "np.save(run_dir / \"config.npy\", config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "init_conds, trajs = load_navier_stokes_tensor(args.data, n_timesteps=args.n_timesteps)\n",
    "init_conds = init_conds.to(device)\n",
    "trajs = trajs.to(device)\n",
    "\n",
    "train_loader, val_loader = setup_dataloaders(init_conds, trajs, batch_size=args.batch_size)\n",
    "P = 3\n",
    "N, T, H, W, Q = trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galerkin_init(param, gain=0.01, diagonal_weight=0.01):\n",
    "    nn.init.xavier_uniform_(param, gain=gain)\n",
    "    param.data += diagonal_weight * torch.diag(torch.ones(param.size(-1), dtype=torch.float, device=param.device))\n",
    "\n",
    "class TrimTransformer(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, dim_feedforward: int, dropout: float, n_layers: int, mask: torch.Tensor | None = None, scale: float | None = None):\n",
    "        super().__init__()\n",
    "\n",
    "        norm_k = nn.LayerNorm(d_model//nhead)\n",
    "        norm_v = nn.LayerNorm(d_model//nhead)\n",
    "        encoder_layer = TrimTransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_k=norm_k,\n",
    "            norm_v=norm_v,\n",
    "            q_weight_init=galerkin_init,\n",
    "            k_weight_init=galerkin_init,\n",
    "            v_weight_init=galerkin_init,\n",
    "            scale=scale,\n",
    "        )\n",
    "        self.mask = mask\n",
    "        self.transformer = TrimTransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, use_kv_cache: bool = False, update_kv_cache: bool = False) -> torch.Tensor:\n",
    "        if self.mask is None:\n",
    "            mask = None\n",
    "        else:\n",
    "            mask = self.mask[:x.shape[1]]\n",
    "        return self.transformer(x, mask=mask, use_kv_cache=use_kv_cache, update_kv_cache=update_kv_cache)\n",
    "\n",
    "    def clear_kv_cache(self):\n",
    "        self.transformer.clear_kv_cache()\n",
    "\n",
    "def make_block_mask_after(n_tokens, block_size):\n",
    "    idx = torch.arange(n_tokens, dtype=torch.long)\n",
    "    mask_after = block_size * ((idx // block_size) + 1)-1\n",
    "    return mask_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set encoder hidden_dim: use provided value or default to d_model - P\n",
    "encoder_hidden_dim = args.encoder_hidden_dim if args.encoder_hidden_dim is not None else args.d_model - P\n",
    "\n",
    "encoder = SingleConvNeuralNet(dim=Q,\n",
    "                                hidden_dim=encoder_hidden_dim,\n",
    "                                out_dim=args.d_model-P,\n",
    "                                hidden_ff=args.encoder_hidden_ff,\n",
    "                                K=args.patch_shape,\n",
    "                                S=args.patch_shape)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Dummy forward pass to get shapes\n",
    "with torch.no_grad():\n",
    "    _, _, H_prime, W_prime, _ = encoder.forward(trajs[0, None, ...].to(device)).shape\n",
    "block_size = H_prime * W_prime\n",
    "\n",
    "if args.refinement:\n",
    "    n_tokens = (args.n_timesteps + 1) * H_prime * W_prime\n",
    "    scale = 1 / n_tokens\n",
    "    mask = None\n",
    "    make_module = partial(TrimTransformer,\n",
    "                    d_model=args.d_model,\n",
    "                    nhead=args.nhead,\n",
    "                    dim_feedforward=args.dim_feedforward,\n",
    "                    dropout=args.dropout,\n",
    "                    n_layers=args.n_layers,\n",
    "                    mask=mask,\n",
    "                    scale=scale)\n",
    "else:\n",
    "    n_tokens = args.n_timesteps * H_prime * W_prime\n",
    "    scale = 1 / n_tokens\n",
    "    mask = make_block_mask_after(n_tokens, block_size).to(device)\n",
    "    make_module = partial(TrimTransformer,\n",
    "                          d_model=args.d_model,\n",
    "                          nhead=args.nhead,\n",
    "                          dim_feedforward=args.dim_feedforward,\n",
    "                          dropout=args.dropout,\n",
    "                          n_layers=args.n_layers,\n",
    "                          mask=mask,\n",
    "                          scale=scale)\n",
    "if args.share:\n",
    "    modules = arch.make_weight_shared_modules(make_module, n_modules=args.n_modules)\n",
    "else:\n",
    "    modules = arch.make_weight_unshared_modules(make_module, n_modules=args.n_modules)\n",
    "if args.picard:\n",
    "    model = arch.PicardIterations(modules, q=Q, r=args.r)\n",
    "else:\n",
    "    model = arch.ArbitraryIterations(modules)\n",
    "model = model.to(device)\n",
    "\n",
    "# Build decoder hidden channels: user-specified channels + fixed output channel\n",
    "decoder_hidden_channels = args.decoder_hidden_channels + [H*W*Q]\n",
    "\n",
    "decoder = MLP(\n",
    "    in_channels=H_prime*W_prime*(args.d_model-P),\n",
    "    hidden_channels=decoder_hidden_channels,\n",
    "    activation_layer=nn.ELU,\n",
    ")\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m train_loss = train_trainer.train_epoch(train_loader, optim)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     val_loss   = val_trainer.eval_epoch(val_loader)\n\u001b[32m     32\u001b[39m scheduler.step()\n\u001b[32m     34\u001b[39m epoch_end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/training.py:174\u001b[39m, in \u001b[36mTrainer.eval_epoch\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader: DataLoader) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._epoch(loader, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/training.py:153\u001b[39m, in \u001b[36mTrainer._epoch\u001b[39m\u001b[34m(self, loader, optim)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_mode:\n\u001b[32m    151\u001b[39m     optim.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m preds = \u001b[38;5;28mself\u001b[39m.predict_fn(init_cond, traj)\n\u001b[32m    154\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.loss_fn(preds, traj)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/training.py:121\u001b[39m, in \u001b[36mCausalMSPipeline.forward\u001b[39m\u001b[34m(self, init_cond, traj)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(traj.shape[\u001b[32m1\u001b[39m]):\n\u001b[32m    120\u001b[39m     last_frame = frames[-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     next_frame = \u001b[38;5;28mself\u001b[39m.step(last_frame)\n\u001b[32m    122\u001b[39m     frames.append(next_frame)\n\u001b[32m    124\u001b[39m pred_traj = torch.cat(frames[\u001b[32m1\u001b[39m:], dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B,T,H,W,Q)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/training.py:95\u001b[39m, in \u001b[36m_CausalMSStepPipeline.forward\u001b[39m\u001b[34m(self, last_frame)\u001b[39m\n\u001b[32m     92\u001b[39m pos = pos.unsqueeze(\u001b[32m0\u001b[39m).expand(B, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     93\u001b[39m tokens = torch.cat([pos, enc_out], dim=-\u001b[32m1\u001b[39m).reshape(B, t*Hp*Wp, C+\u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m model_out = \u001b[38;5;28mself\u001b[39m.model(tokens, use_kv_cache=\u001b[38;5;28;01mTrue\u001b[39;00m, update_kv_cache=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     96\u001b[39m preds_enc = model_out[..., -C:]\n\u001b[32m     97\u001b[39m preds_spatial = preds_enc.view(B, t, Hp, Wp, C)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/architectures.py:28\u001b[39m, in \u001b[36mPicardIterations.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         x = step(x, *args, **kwargs)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lambda/nfs/anie-experiments/twin/architectures.py:50\u001b[39m, in \u001b[36mPicardStep.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.model(x, *args, **kwargs)\n\u001b[32m     51\u001b[39m     y = \u001b[38;5;28mself\u001b[39m.r * x[..., -\u001b[38;5;28mself\u001b[39m.q:] + (\u001b[32m1\u001b[39m-\u001b[38;5;28mself\u001b[39m.r) * z[..., -\u001b[38;5;28mself\u001b[39m.q:]\n\u001b[32m     52\u001b[39m     y_ = torch.cat([x[..., :-\u001b[38;5;28mself\u001b[39m.q], y], dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mTrimTransformer.forward\u001b[39m\u001b[34m(self, x, use_kv_cache, update_kv_cache)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     31\u001b[39m     mask = \u001b[38;5;28mself\u001b[39m.mask[:x.shape[\u001b[32m1\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer(x, mask=mask, use_kv_cache=use_kv_cache, update_kv_cache=update_kv_cache)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/trim_transformer/transformer_layers.py:264\u001b[39m, in \u001b[36mTrimTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal, use_kv_cache, update_kv_cache)\u001b[39m\n\u001b[32m    261\u001b[39m     is_causal = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     output = mod(\n\u001b[32m    265\u001b[39m         output,\n\u001b[32m    266\u001b[39m         mask=mask,\n\u001b[32m    267\u001b[39m         is_causal=is_causal,\n\u001b[32m    268\u001b[39m         src_key_padding_mask=src_key_padding_mask,\n\u001b[32m    269\u001b[39m         use_kv_cache=use_kv_cache,\n\u001b[32m    270\u001b[39m         update_kv_cache=update_kv_cache,\n\u001b[32m    271\u001b[39m     )\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    274\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.norm(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/trim_transformer/transformer_layers.py:164\u001b[39m, in \u001b[36mTrimTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal, use_kv_cache, update_kv_cache)\u001b[39m\n\u001b[32m    161\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m         x + \u001b[38;5;28mself\u001b[39m._sa_block(x, mask, src_key_padding_mask, is_causal=is_causal,\n\u001b[32m    165\u001b[39m                          use_kv_cache=use_kv_cache, update_kv_cache=update_kv_cache)\n\u001b[32m    166\u001b[39m     )\n\u001b[32m    167\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/trim_transformer/transformer_layers.py:181\u001b[39m, in \u001b[36mTrimTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, mask, src_key_padding_mask, is_causal, use_kv_cache, update_kv_cache)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    174\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     update_kv_cache: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    180\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    182\u001b[39m         x,\n\u001b[32m    183\u001b[39m         x,\n\u001b[32m    184\u001b[39m         x,\n\u001b[32m    185\u001b[39m         mask=mask,\n\u001b[32m    186\u001b[39m         src_key_padding_mask=src_key_padding_mask,\n\u001b[32m    187\u001b[39m         is_causal=is_causal,\n\u001b[32m    188\u001b[39m         use_kv_cache=use_kv_cache,\n\u001b[32m    189\u001b[39m         update_kv_cache=update_kv_cache,\n\u001b[32m    190\u001b[39m     )\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/trim_transformer/modules.py:191\u001b[39m, in \u001b[36mTrimMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, is_causal, mask, src_key_padding_mask, use_kv_cache, update_kv_cache)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm_v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     v = \u001b[38;5;28mself\u001b[39m.norm_v(v)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m attn_output, key_value_store = multi_linear_attn(\n\u001b[32m    192\u001b[39m     q, k, v, \n\u001b[32m    193\u001b[39m     mask=mask,\n\u001b[32m    194\u001b[39m     dropout_p=dropout_p,\n\u001b[32m    195\u001b[39m     is_causal=is_causal,\n\u001b[32m    196\u001b[39m     scale=\u001b[38;5;28mself\u001b[39m.scale,\n\u001b[32m    197\u001b[39m     enable_gqa=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    198\u001b[39m     kv_cache=kv_cache\n\u001b[32m    199\u001b[39m )\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update_kv_cache:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m.kv_cache = key_value_store[:, :, -\u001b[32m1\u001b[39m:, :, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/twin/lib/python3.13/site-packages/trim_transformer/functional.py:30\u001b[39m, in \u001b[36mmulti_linear_attn\u001b[39m\u001b[34m(query, key, value, mask, dropout_p, is_causal, scale, enable_gqa, kv_cache)\u001b[39m\n\u001b[32m     28\u001b[39m value = value.unsqueeze(-\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# [..., S, 1, d_v]\u001b[39;00m\n\u001b[32m     29\u001b[39m key_value_store = key @ value  \u001b[38;5;66;03m# [..., S, d_k, d_v]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m key_value_store = key_value_store.cumsum(dim=-\u001b[32m3\u001b[39m)[..., mask, :, :] + kv_cache\n\u001b[32m     31\u001b[39m key_value_store = torch.dropout(key_value_store, dropout_p, train=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (query.unsqueeze(-\u001b[32m2\u001b[39m) @ key_value_store).squeeze(-\u001b[32m2\u001b[39m), key_value_store\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "loss_fn = F.mse_loss\n",
    "optim = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(encoder.parameters()) + list(decoder.parameters()), lr=args.lr, weight_decay=args.weight_decay\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=args.T_max, eta_min=args.min_lr)\n",
    "\n",
    "train_pipeline = build_pipeline(args.train_kind,\n",
    "                                encoder=encoder,\n",
    "                                model=model,\n",
    "                                decoder=decoder)\n",
    "\n",
    "val_pipeline = build_pipeline(args.val_kind,\n",
    "                              encoder=encoder,\n",
    "                              model=model,\n",
    "                              decoder=decoder)\n",
    "\n",
    "train_trainer = Trainer(train_pipeline, loss_fn, grad_clip_norm=args.grad_clip_norm)\n",
    "\n",
    "val_trainer = Trainer(val_pipeline, loss_fn)\n",
    "\n",
    "# Initialize lists to track losses and times\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epoch_times = []\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    train_loss = train_trainer.train_epoch(train_loader, optim)\n",
    "    with torch.no_grad():\n",
    "        val_loss   = val_trainer.eval_epoch(val_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Append losses and times to tracking lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    print(f\"{args.name} | Epoch {epoch:3d} | train loss: {train_loss:.6f} | val loss: {val_loss:.6f} | time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Save losses and times as numpy arrays every epoch in run directory\n",
    "    np.save(run_dir / \"train_loss.npy\", np.array(train_losses))\n",
    "    np.save(run_dir / \"val_loss.npy\", np.array(val_losses))\n",
    "    np.save(run_dir / \"epoch_times.npy\", np.array(epoch_times))\n",
    "\n",
    "# Save model weights in run directory\n",
    "torch.save({\"state_dict\": model.state_dict()}, run_dir / \"model_weights.pt\")\n",
    "\n",
    "# Save final loss arrays and times in run directory\n",
    "np.save(run_dir / \"train_loss.npy\", np.array(train_losses))\n",
    "np.save(run_dir / \"val_loss.npy\", np.array(val_losses))\n",
    "np.save(run_dir / \"epoch_times.npy\", np.array(epoch_times))\n",
    "\n",
    "print(f\"\\nTraining completed! All files saved to: {run_dir}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final val loss: {val_losses[-1]:.6f}\")\n",
    "print(f\"Average epoch time: {np.mean(epoch_times):.2f}s\")\n",
    "print(f\"Total training time: {np.sum(epoch_times):.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
